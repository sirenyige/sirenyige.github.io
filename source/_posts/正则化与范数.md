---
title: 正则化与范数
date: 2020-06-11 00:06:40
categories:
- 机器学习
tags:
- 正则化
---

# 正则化与范数

<!-- more -->

## 一、正则化

正则化是结构风险最小化策略的实现，其在经验风险上加上一个正则化项。正则化项一般为模型复杂度的单调递增函数，模型越复杂，正则化值就越大。比如，正则化项可以是模型参数向量的范数。一般具有如下形式：
$$
\min_{f}\frac{1}{N}\sum_{i=1}^{N}L\left ( y_i,f\left ( x_i\right )\right )+\lambda J\left ( f\right )
$$
其中，第一项是经验风险，第二项是正则化项，$\lambda\geqslant 0$为调整两者之间关系的系数。

## 二、范数

不同范数对应的曲线如下图：

<img src="/正则化与范数/范数图像.jpg" alt="范数图像" style="zoom: 50%;" />

q越小，曲线越贴近坐标轴；q越大，曲线越远离坐标轴，并且棱角越明显。那么 q=0时极限逼近于十字架， 和 q=oo时极限逼近正方形。

q大于1，q范数为凸函数；q小于1，q范数不为凸函数。范数的凸性对求解最优化问题很重要。

## 三、范数与正则化

以1范数和2范数为例：

<img src="/正则化与范数/范数图像1.jpg" alt="范数图像1" style="zoom: 50%;" />

蓝色的圆圈表示原问题可能的解范围，橘色的表示正则项可能的解范围。而整个目标函数（原问题+正则项）有解当且仅当两个解范围相切。

从上图可以很容易地看出，由于2范数解范围是圆，所以相切的点有很大可能不在坐标轴上，而由于1范数是菱形（顶点是凸出来的），其相切的点更可能在坐标轴上，而坐标轴上的点有一个特点，其只有一个坐标分量不为零，其他坐标分量为零，即是稀疏的。

### 1、L0范数

L0范数表示向量中非零元素的数量。如果用L0范数作为正则项，就是希望模型中大部分参数为零，实现稀疏。

但是在机器学习中，特征的维度往往很大，解L0范数又是NP-hard问题，所以在实际中不可行。

### 2、L1范数

L1范数表示向量中各个元素绝对值之和，也叫“系数规则算子”。L1范数也可实现稀疏，且为L0的最优凸近似，比L0更易求解，所以实际稀疏模型中用L1范数约束。

### 3、L2范数

L2范数表示向量中各个元素的平方和然后开方。L2范数作为正则项，可以使得模型的每一个参数都比较小，但与L1不同的是，不会为0；这样的模型抗干扰能力强，参数很小时，即使样本数据发生较大变化，对预测值的影响也会很有限。

[1]: https://www.zhihu.com/question/20473040	"0 范数、1 范数、2 范数有什么区别？"